{
  "best_metric": 4.792965773958713e-05,
  "best_model_checkpoint": "/workspace/rtp/CF-PepMLM/checkpoints/checkpoint-2000",
  "epoch": 9.216589861751151,
  "eval_steps": 100,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04608294930875576,
      "grad_norm": 1.2221239805221558,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.7734,
      "step": 10
    },
    {
      "epoch": 0.09216589861751152,
      "grad_norm": 1.2903002500534058,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.795,
      "step": 20
    },
    {
      "epoch": 0.1382488479262673,
      "grad_norm": 0.9074258208274841,
      "learning_rate": 3e-06,
      "loss": 0.7743,
      "step": 30
    },
    {
      "epoch": 0.18433179723502305,
      "grad_norm": 1.1783366203308105,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.7928,
      "step": 40
    },
    {
      "epoch": 0.2304147465437788,
      "grad_norm": 0.913509726524353,
      "learning_rate": 5e-06,
      "loss": 0.7656,
      "step": 50
    },
    {
      "epoch": 0.2764976958525346,
      "grad_norm": 0.971287727355957,
      "learning_rate": 6e-06,
      "loss": 0.7406,
      "step": 60
    },
    {
      "epoch": 0.3225806451612903,
      "grad_norm": 0.8465772271156311,
      "learning_rate": 7.000000000000001e-06,
      "loss": 0.7102,
      "step": 70
    },
    {
      "epoch": 0.3686635944700461,
      "grad_norm": 1.177011489868164,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.6897,
      "step": 80
    },
    {
      "epoch": 0.4147465437788018,
      "grad_norm": 1.1783441305160522,
      "learning_rate": 9e-06,
      "loss": 0.6719,
      "step": 90
    },
    {
      "epoch": 0.4608294930875576,
      "grad_norm": 1.2005335092544556,
      "learning_rate": 1e-05,
      "loss": 0.606,
      "step": 100
    },
    {
      "epoch": 0.4608294930875576,
      "eval_loss": 0.5518519282341003,
      "eval_runtime": 3.8436,
      "eval_samples_per_second": 56.717,
      "eval_steps_per_second": 7.285,
      "step": 100
    },
    {
      "epoch": 0.5069124423963134,
      "grad_norm": 1.5589687824249268,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.5516,
      "step": 110
    },
    {
      "epoch": 0.5529953917050692,
      "grad_norm": 1.4523738622665405,
      "learning_rate": 1.2e-05,
      "loss": 0.5204,
      "step": 120
    },
    {
      "epoch": 0.5990783410138248,
      "grad_norm": 1.247963309288025,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.3851,
      "step": 130
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 1.0782917737960815,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.3266,
      "step": 140
    },
    {
      "epoch": 0.6912442396313364,
      "grad_norm": 0.7613620162010193,
      "learning_rate": 1.5e-05,
      "loss": 0.2864,
      "step": 150
    },
    {
      "epoch": 0.7373271889400922,
      "grad_norm": 0.9301382899284363,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.258,
      "step": 160
    },
    {
      "epoch": 0.783410138248848,
      "grad_norm": 0.9205523729324341,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.2286,
      "step": 170
    },
    {
      "epoch": 0.8294930875576036,
      "grad_norm": 0.7904914617538452,
      "learning_rate": 1.8e-05,
      "loss": 0.201,
      "step": 180
    },
    {
      "epoch": 0.8755760368663594,
      "grad_norm": 0.6755183339118958,
      "learning_rate": 1.9e-05,
      "loss": 0.1537,
      "step": 190
    },
    {
      "epoch": 0.9216589861751152,
      "grad_norm": 0.7571019530296326,
      "learning_rate": 2e-05,
      "loss": 0.1209,
      "step": 200
    },
    {
      "epoch": 0.9216589861751152,
      "eval_loss": 0.08680877089500427,
      "eval_runtime": 3.468,
      "eval_samples_per_second": 62.86,
      "eval_steps_per_second": 8.074,
      "step": 200
    },
    {
      "epoch": 0.967741935483871,
      "grad_norm": 0.7238255739212036,
      "learning_rate": 2.1e-05,
      "loss": 0.1068,
      "step": 210
    },
    {
      "epoch": 1.0138248847926268,
      "grad_norm": 0.47162294387817383,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.0876,
      "step": 220
    },
    {
      "epoch": 1.0599078341013826,
      "grad_norm": 0.5361238718032837,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.0793,
      "step": 230
    },
    {
      "epoch": 1.1059907834101383,
      "grad_norm": 0.4974692165851593,
      "learning_rate": 2.4e-05,
      "loss": 0.0589,
      "step": 240
    },
    {
      "epoch": 1.1520737327188941,
      "grad_norm": 0.46764472126960754,
      "learning_rate": 2.5e-05,
      "loss": 0.0515,
      "step": 250
    },
    {
      "epoch": 1.1981566820276497,
      "grad_norm": 0.6306203603744507,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.0537,
      "step": 260
    },
    {
      "epoch": 1.2442396313364055,
      "grad_norm": 0.48413780331611633,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.0377,
      "step": 270
    },
    {
      "epoch": 1.2903225806451613,
      "grad_norm": 0.48220014572143555,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.0377,
      "step": 280
    },
    {
      "epoch": 1.336405529953917,
      "grad_norm": 0.26070141792297363,
      "learning_rate": 2.9e-05,
      "loss": 0.0353,
      "step": 290
    },
    {
      "epoch": 1.3824884792626728,
      "grad_norm": 0.2717057764530182,
      "learning_rate": 3e-05,
      "loss": 0.0317,
      "step": 300
    },
    {
      "epoch": 1.3824884792626728,
      "eval_loss": 0.018590880557894707,
      "eval_runtime": 3.6498,
      "eval_samples_per_second": 59.73,
      "eval_steps_per_second": 7.672,
      "step": 300
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.5223829746246338,
      "learning_rate": 3.1e-05,
      "loss": 0.0365,
      "step": 310
    },
    {
      "epoch": 1.4746543778801844,
      "grad_norm": 0.340888649225235,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.0279,
      "step": 320
    },
    {
      "epoch": 1.52073732718894,
      "grad_norm": 0.3112410306930542,
      "learning_rate": 3.3e-05,
      "loss": 0.0262,
      "step": 330
    },
    {
      "epoch": 1.5668202764976957,
      "grad_norm": 0.29125121235847473,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0221,
      "step": 340
    },
    {
      "epoch": 1.6129032258064515,
      "grad_norm": 0.41481947898864746,
      "learning_rate": 3.5e-05,
      "loss": 0.021,
      "step": 350
    },
    {
      "epoch": 1.6589861751152073,
      "grad_norm": 0.33511883020401,
      "learning_rate": 3.6e-05,
      "loss": 0.0206,
      "step": 360
    },
    {
      "epoch": 1.705069124423963,
      "grad_norm": 0.41893166303634644,
      "learning_rate": 3.7e-05,
      "loss": 0.0135,
      "step": 370
    },
    {
      "epoch": 1.7511520737327189,
      "grad_norm": 0.357644259929657,
      "learning_rate": 3.8e-05,
      "loss": 0.022,
      "step": 380
    },
    {
      "epoch": 1.7972350230414746,
      "grad_norm": 0.18183016777038574,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.0123,
      "step": 390
    },
    {
      "epoch": 1.8433179723502304,
      "grad_norm": 0.29831454157829285,
      "learning_rate": 4e-05,
      "loss": 0.0135,
      "step": 400
    },
    {
      "epoch": 1.8433179723502304,
      "eval_loss": 0.0062129441648721695,
      "eval_runtime": 4.0426,
      "eval_samples_per_second": 53.926,
      "eval_steps_per_second": 6.926,
      "step": 400
    },
    {
      "epoch": 1.8894009216589862,
      "grad_norm": 0.22957932949066162,
      "learning_rate": 4.1e-05,
      "loss": 0.0123,
      "step": 410
    },
    {
      "epoch": 1.935483870967742,
      "grad_norm": 0.16631853580474854,
      "learning_rate": 4.2e-05,
      "loss": 0.0101,
      "step": 420
    },
    {
      "epoch": 1.9815668202764978,
      "grad_norm": 0.3713280260562897,
      "learning_rate": 4.3e-05,
      "loss": 0.0133,
      "step": 430
    },
    {
      "epoch": 2.0276497695852536,
      "grad_norm": 0.24464811384677887,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.0122,
      "step": 440
    },
    {
      "epoch": 2.0737327188940093,
      "grad_norm": 0.14365676045417786,
      "learning_rate": 4.5e-05,
      "loss": 0.009,
      "step": 450
    },
    {
      "epoch": 2.119815668202765,
      "grad_norm": 0.37955477833747864,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.011,
      "step": 460
    },
    {
      "epoch": 2.165898617511521,
      "grad_norm": 0.34527018666267395,
      "learning_rate": 4.7e-05,
      "loss": 0.0103,
      "step": 470
    },
    {
      "epoch": 2.2119815668202767,
      "grad_norm": 0.21032993495464325,
      "learning_rate": 4.8e-05,
      "loss": 0.0082,
      "step": 480
    },
    {
      "epoch": 2.258064516129032,
      "grad_norm": 0.17407621443271637,
      "learning_rate": 4.9e-05,
      "loss": 0.0073,
      "step": 490
    },
    {
      "epoch": 2.3041474654377883,
      "grad_norm": 0.30856654047966003,
      "learning_rate": 5e-05,
      "loss": 0.0103,
      "step": 500
    },
    {
      "epoch": 2.3041474654377883,
      "eval_loss": 0.0030326282139867544,
      "eval_runtime": 5.337,
      "eval_samples_per_second": 40.847,
      "eval_steps_per_second": 5.246,
      "step": 500
    },
    {
      "epoch": 2.3502304147465436,
      "grad_norm": 0.23411279916763306,
      "learning_rate": 4.970059880239521e-05,
      "loss": 0.0087,
      "step": 510
    },
    {
      "epoch": 2.3963133640552994,
      "grad_norm": 0.18469040095806122,
      "learning_rate": 4.9401197604790424e-05,
      "loss": 0.0057,
      "step": 520
    },
    {
      "epoch": 2.442396313364055,
      "grad_norm": 0.15716958045959473,
      "learning_rate": 4.910179640718563e-05,
      "loss": 0.006,
      "step": 530
    },
    {
      "epoch": 2.488479262672811,
      "grad_norm": 0.10877557098865509,
      "learning_rate": 4.8802395209580846e-05,
      "loss": 0.0076,
      "step": 540
    },
    {
      "epoch": 2.5345622119815667,
      "grad_norm": 0.18851915001869202,
      "learning_rate": 4.8502994011976046e-05,
      "loss": 0.0078,
      "step": 550
    },
    {
      "epoch": 2.5806451612903225,
      "grad_norm": 0.1537848562002182,
      "learning_rate": 4.820359281437126e-05,
      "loss": 0.0048,
      "step": 560
    },
    {
      "epoch": 2.6267281105990783,
      "grad_norm": 0.18426953256130219,
      "learning_rate": 4.790419161676647e-05,
      "loss": 0.0043,
      "step": 570
    },
    {
      "epoch": 2.672811059907834,
      "grad_norm": 0.19603843986988068,
      "learning_rate": 4.7604790419161675e-05,
      "loss": 0.0048,
      "step": 580
    },
    {
      "epoch": 2.71889400921659,
      "grad_norm": 0.09878431260585785,
      "learning_rate": 4.730538922155689e-05,
      "loss": 0.008,
      "step": 590
    },
    {
      "epoch": 2.7649769585253456,
      "grad_norm": 0.1926334798336029,
      "learning_rate": 4.70059880239521e-05,
      "loss": 0.0051,
      "step": 600
    },
    {
      "epoch": 2.7649769585253456,
      "eval_loss": 0.0014930713223293424,
      "eval_runtime": 3.711,
      "eval_samples_per_second": 58.745,
      "eval_steps_per_second": 7.545,
      "step": 600
    },
    {
      "epoch": 2.8110599078341014,
      "grad_norm": 0.11369042843580246,
      "learning_rate": 4.670658682634731e-05,
      "loss": 0.0055,
      "step": 610
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.1356334388256073,
      "learning_rate": 4.640718562874252e-05,
      "loss": 0.0036,
      "step": 620
    },
    {
      "epoch": 2.903225806451613,
      "grad_norm": 0.20589186251163483,
      "learning_rate": 4.610778443113773e-05,
      "loss": 0.006,
      "step": 630
    },
    {
      "epoch": 2.9493087557603688,
      "grad_norm": 0.1344430148601532,
      "learning_rate": 4.580838323353293e-05,
      "loss": 0.0025,
      "step": 640
    },
    {
      "epoch": 2.9953917050691246,
      "grad_norm": 0.18633319437503815,
      "learning_rate": 4.550898203592814e-05,
      "loss": 0.0042,
      "step": 650
    },
    {
      "epoch": 3.0414746543778803,
      "grad_norm": 0.18155881762504578,
      "learning_rate": 4.5209580838323355e-05,
      "loss": 0.0044,
      "step": 660
    },
    {
      "epoch": 3.087557603686636,
      "grad_norm": 0.1386127471923828,
      "learning_rate": 4.491017964071856e-05,
      "loss": 0.0033,
      "step": 670
    },
    {
      "epoch": 3.133640552995392,
      "grad_norm": 0.15597963333129883,
      "learning_rate": 4.4610778443113777e-05,
      "loss": 0.003,
      "step": 680
    },
    {
      "epoch": 3.1797235023041477,
      "grad_norm": 0.12742440402507782,
      "learning_rate": 4.4311377245508984e-05,
      "loss": 0.0033,
      "step": 690
    },
    {
      "epoch": 3.225806451612903,
      "grad_norm": 0.027078034356236458,
      "learning_rate": 4.40119760479042e-05,
      "loss": 0.0012,
      "step": 700
    },
    {
      "epoch": 3.225806451612903,
      "eval_loss": 0.0009080949239432812,
      "eval_runtime": 3.7791,
      "eval_samples_per_second": 57.686,
      "eval_steps_per_second": 7.409,
      "step": 700
    },
    {
      "epoch": 3.271889400921659,
      "grad_norm": 0.25669535994529724,
      "learning_rate": 4.3712574850299406e-05,
      "loss": 0.0038,
      "step": 710
    },
    {
      "epoch": 3.3179723502304146,
      "grad_norm": 0.2486574500799179,
      "learning_rate": 4.341317365269461e-05,
      "loss": 0.0047,
      "step": 720
    },
    {
      "epoch": 3.3640552995391704,
      "grad_norm": 0.20283110439777374,
      "learning_rate": 4.311377245508982e-05,
      "loss": 0.0023,
      "step": 730
    },
    {
      "epoch": 3.410138248847926,
      "grad_norm": 0.0888674184679985,
      "learning_rate": 4.281437125748503e-05,
      "loss": 0.0017,
      "step": 740
    },
    {
      "epoch": 3.456221198156682,
      "grad_norm": 0.17090241611003876,
      "learning_rate": 4.251497005988024e-05,
      "loss": 0.0025,
      "step": 750
    },
    {
      "epoch": 3.5023041474654377,
      "grad_norm": 0.19521477818489075,
      "learning_rate": 4.221556886227545e-05,
      "loss": 0.0033,
      "step": 760
    },
    {
      "epoch": 3.5483870967741935,
      "grad_norm": 0.07247144728899002,
      "learning_rate": 4.191616766467066e-05,
      "loss": 0.0014,
      "step": 770
    },
    {
      "epoch": 3.5944700460829493,
      "grad_norm": 0.14422035217285156,
      "learning_rate": 4.161676646706587e-05,
      "loss": 0.0027,
      "step": 780
    },
    {
      "epoch": 3.640552995391705,
      "grad_norm": 0.05749085545539856,
      "learning_rate": 4.131736526946108e-05,
      "loss": 0.0027,
      "step": 790
    },
    {
      "epoch": 3.686635944700461,
      "grad_norm": 0.11122436821460724,
      "learning_rate": 4.101796407185629e-05,
      "loss": 0.0017,
      "step": 800
    },
    {
      "epoch": 3.686635944700461,
      "eval_loss": 0.000741194817237556,
      "eval_runtime": 3.2183,
      "eval_samples_per_second": 67.737,
      "eval_steps_per_second": 8.7,
      "step": 800
    },
    {
      "epoch": 3.7327188940092166,
      "grad_norm": 0.16310246288776398,
      "learning_rate": 4.07185628742515e-05,
      "loss": 0.006,
      "step": 810
    },
    {
      "epoch": 3.7788018433179724,
      "grad_norm": 0.27053704857826233,
      "learning_rate": 4.041916167664671e-05,
      "loss": 0.0031,
      "step": 820
    },
    {
      "epoch": 3.824884792626728,
      "grad_norm": 0.03771095722913742,
      "learning_rate": 4.0119760479041915e-05,
      "loss": 0.0018,
      "step": 830
    },
    {
      "epoch": 3.870967741935484,
      "grad_norm": 0.2837746739387512,
      "learning_rate": 3.982035928143712e-05,
      "loss": 0.0039,
      "step": 840
    },
    {
      "epoch": 3.9170506912442398,
      "grad_norm": 0.3046124279499054,
      "learning_rate": 3.9520958083832336e-05,
      "loss": 0.0027,
      "step": 850
    },
    {
      "epoch": 3.9631336405529956,
      "grad_norm": 0.06274067610502243,
      "learning_rate": 3.9221556886227544e-05,
      "loss": 0.0029,
      "step": 860
    },
    {
      "epoch": 4.009216589861751,
      "grad_norm": 0.1926690936088562,
      "learning_rate": 3.892215568862276e-05,
      "loss": 0.0052,
      "step": 870
    },
    {
      "epoch": 4.055299539170507,
      "grad_norm": 0.07665092498064041,
      "learning_rate": 3.8622754491017966e-05,
      "loss": 0.0014,
      "step": 880
    },
    {
      "epoch": 4.1013824884792625,
      "grad_norm": 0.06854434311389923,
      "learning_rate": 3.832335329341318e-05,
      "loss": 0.0013,
      "step": 890
    },
    {
      "epoch": 4.147465437788019,
      "grad_norm": 0.038714054971933365,
      "learning_rate": 3.802395209580839e-05,
      "loss": 0.0009,
      "step": 900
    },
    {
      "epoch": 4.147465437788019,
      "eval_loss": 0.0004275927203707397,
      "eval_runtime": 2.477,
      "eval_samples_per_second": 88.011,
      "eval_steps_per_second": 11.304,
      "step": 900
    },
    {
      "epoch": 4.193548387096774,
      "grad_norm": 0.1802065670490265,
      "learning_rate": 3.7724550898203595e-05,
      "loss": 0.0029,
      "step": 910
    },
    {
      "epoch": 4.23963133640553,
      "grad_norm": 0.0067209540866315365,
      "learning_rate": 3.74251497005988e-05,
      "loss": 0.001,
      "step": 920
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.11563533544540405,
      "learning_rate": 3.712574850299401e-05,
      "loss": 0.0018,
      "step": 930
    },
    {
      "epoch": 4.331797235023042,
      "grad_norm": 0.1913885623216629,
      "learning_rate": 3.6826347305389224e-05,
      "loss": 0.0032,
      "step": 940
    },
    {
      "epoch": 4.377880184331797,
      "grad_norm": 0.006824429612606764,
      "learning_rate": 3.652694610778443e-05,
      "loss": 0.0013,
      "step": 950
    },
    {
      "epoch": 4.423963133640553,
      "grad_norm": 0.12576280534267426,
      "learning_rate": 3.6227544910179645e-05,
      "loss": 0.0018,
      "step": 960
    },
    {
      "epoch": 4.470046082949309,
      "grad_norm": 0.21926555037498474,
      "learning_rate": 3.592814371257485e-05,
      "loss": 0.0023,
      "step": 970
    },
    {
      "epoch": 4.516129032258064,
      "grad_norm": 0.15565291047096252,
      "learning_rate": 3.562874251497006e-05,
      "loss": 0.0008,
      "step": 980
    },
    {
      "epoch": 4.56221198156682,
      "grad_norm": 0.031143641099333763,
      "learning_rate": 3.5329341317365274e-05,
      "loss": 0.0013,
      "step": 990
    },
    {
      "epoch": 4.6082949308755765,
      "grad_norm": 0.15209895372390747,
      "learning_rate": 3.502994011976048e-05,
      "loss": 0.0014,
      "step": 1000
    },
    {
      "epoch": 4.6082949308755765,
      "eval_loss": 0.0003016693517565727,
      "eval_runtime": 3.3643,
      "eval_samples_per_second": 64.799,
      "eval_steps_per_second": 8.323,
      "step": 1000
    },
    {
      "epoch": 4.654377880184332,
      "grad_norm": 0.4421521723270416,
      "learning_rate": 3.473053892215569e-05,
      "loss": 0.002,
      "step": 1010
    },
    {
      "epoch": 4.700460829493087,
      "grad_norm": 0.22716058790683746,
      "learning_rate": 3.4431137724550896e-05,
      "loss": 0.0024,
      "step": 1020
    },
    {
      "epoch": 4.746543778801843,
      "grad_norm": 0.013918216340243816,
      "learning_rate": 3.413173652694611e-05,
      "loss": 0.0017,
      "step": 1030
    },
    {
      "epoch": 4.792626728110599,
      "grad_norm": 0.01610390469431877,
      "learning_rate": 3.383233532934132e-05,
      "loss": 0.0013,
      "step": 1040
    },
    {
      "epoch": 4.838709677419355,
      "grad_norm": 0.14356395602226257,
      "learning_rate": 3.3532934131736525e-05,
      "loss": 0.0007,
      "step": 1050
    },
    {
      "epoch": 4.88479262672811,
      "grad_norm": 0.01901886984705925,
      "learning_rate": 3.323353293413174e-05,
      "loss": 0.0008,
      "step": 1060
    },
    {
      "epoch": 4.9308755760368665,
      "grad_norm": 0.013008169829845428,
      "learning_rate": 3.293413173652695e-05,
      "loss": 0.001,
      "step": 1070
    },
    {
      "epoch": 4.976958525345622,
      "grad_norm": 0.013123435899615288,
      "learning_rate": 3.263473053892216e-05,
      "loss": 0.0017,
      "step": 1080
    },
    {
      "epoch": 5.023041474654378,
      "grad_norm": 0.07366488873958588,
      "learning_rate": 3.233532934131737e-05,
      "loss": 0.0008,
      "step": 1090
    },
    {
      "epoch": 5.0691244239631335,
      "grad_norm": 0.06365758925676346,
      "learning_rate": 3.2035928143712576e-05,
      "loss": 0.0015,
      "step": 1100
    },
    {
      "epoch": 5.0691244239631335,
      "eval_loss": 0.00022336501569952816,
      "eval_runtime": 3.2679,
      "eval_samples_per_second": 66.709,
      "eval_steps_per_second": 8.568,
      "step": 1100
    },
    {
      "epoch": 5.11520737327189,
      "grad_norm": 0.07288898527622223,
      "learning_rate": 3.1736526946107784e-05,
      "loss": 0.0013,
      "step": 1110
    },
    {
      "epoch": 5.161290322580645,
      "grad_norm": 0.1547965407371521,
      "learning_rate": 3.143712574850299e-05,
      "loss": 0.0013,
      "step": 1120
    },
    {
      "epoch": 5.207373271889401,
      "grad_norm": 0.03308495879173279,
      "learning_rate": 3.1137724550898205e-05,
      "loss": 0.0012,
      "step": 1130
    },
    {
      "epoch": 5.253456221198157,
      "grad_norm": 0.017583414912223816,
      "learning_rate": 3.083832335329341e-05,
      "loss": 0.0013,
      "step": 1140
    },
    {
      "epoch": 5.299539170506913,
      "grad_norm": 0.003020468633621931,
      "learning_rate": 3.053892215568863e-05,
      "loss": 0.0011,
      "step": 1150
    },
    {
      "epoch": 5.345622119815668,
      "grad_norm": 0.16190949082374573,
      "learning_rate": 3.0239520958083834e-05,
      "loss": 0.0009,
      "step": 1160
    },
    {
      "epoch": 5.391705069124424,
      "grad_norm": 0.06604956090450287,
      "learning_rate": 2.994011976047904e-05,
      "loss": 0.0008,
      "step": 1170
    },
    {
      "epoch": 5.43778801843318,
      "grad_norm": 0.024254150688648224,
      "learning_rate": 2.9640718562874252e-05,
      "loss": 0.0008,
      "step": 1180
    },
    {
      "epoch": 5.483870967741936,
      "grad_norm": 0.2321062982082367,
      "learning_rate": 2.934131736526946e-05,
      "loss": 0.0018,
      "step": 1190
    },
    {
      "epoch": 5.529953917050691,
      "grad_norm": 0.03868813440203667,
      "learning_rate": 2.9041916167664674e-05,
      "loss": 0.0008,
      "step": 1200
    },
    {
      "epoch": 5.529953917050691,
      "eval_loss": 0.00017234368715435266,
      "eval_runtime": 3.4132,
      "eval_samples_per_second": 63.869,
      "eval_steps_per_second": 8.203,
      "step": 1200
    },
    {
      "epoch": 5.576036866359447,
      "grad_norm": 0.062269728630781174,
      "learning_rate": 2.874251497005988e-05,
      "loss": 0.0016,
      "step": 1210
    },
    {
      "epoch": 5.622119815668203,
      "grad_norm": 0.013919398188591003,
      "learning_rate": 2.8443113772455092e-05,
      "loss": 0.0012,
      "step": 1220
    },
    {
      "epoch": 5.668202764976958,
      "grad_norm": 0.20949777960777283,
      "learning_rate": 2.81437125748503e-05,
      "loss": 0.0018,
      "step": 1230
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.05616622045636177,
      "learning_rate": 2.7844311377245507e-05,
      "loss": 0.0005,
      "step": 1240
    },
    {
      "epoch": 5.76036866359447,
      "grad_norm": 0.06490331888198853,
      "learning_rate": 2.754491017964072e-05,
      "loss": 0.0009,
      "step": 1250
    },
    {
      "epoch": 5.806451612903226,
      "grad_norm": 0.02045886218547821,
      "learning_rate": 2.724550898203593e-05,
      "loss": 0.001,
      "step": 1260
    },
    {
      "epoch": 5.852534562211981,
      "grad_norm": 0.04542779177427292,
      "learning_rate": 2.694610778443114e-05,
      "loss": 0.001,
      "step": 1270
    },
    {
      "epoch": 5.8986175115207375,
      "grad_norm": 0.029611457139253616,
      "learning_rate": 2.6646706586826347e-05,
      "loss": 0.0006,
      "step": 1280
    },
    {
      "epoch": 5.944700460829493,
      "grad_norm": 0.11866834759712219,
      "learning_rate": 2.634730538922156e-05,
      "loss": 0.0011,
      "step": 1290
    },
    {
      "epoch": 5.990783410138249,
      "grad_norm": 0.003626300720497966,
      "learning_rate": 2.604790419161677e-05,
      "loss": 0.0007,
      "step": 1300
    },
    {
      "epoch": 5.990783410138249,
      "eval_loss": 0.0001315186673309654,
      "eval_runtime": 3.442,
      "eval_samples_per_second": 63.335,
      "eval_steps_per_second": 8.135,
      "step": 1300
    },
    {
      "epoch": 6.0368663594470044,
      "grad_norm": 0.027130573987960815,
      "learning_rate": 2.5748502994011976e-05,
      "loss": 0.001,
      "step": 1310
    },
    {
      "epoch": 6.082949308755761,
      "grad_norm": 0.02263498306274414,
      "learning_rate": 2.5449101796407187e-05,
      "loss": 0.0003,
      "step": 1320
    },
    {
      "epoch": 6.129032258064516,
      "grad_norm": 0.01771031692624092,
      "learning_rate": 2.5149700598802394e-05,
      "loss": 0.0014,
      "step": 1330
    },
    {
      "epoch": 6.175115207373272,
      "grad_norm": 0.004386354703456163,
      "learning_rate": 2.4850299401197605e-05,
      "loss": 0.0018,
      "step": 1340
    },
    {
      "epoch": 6.221198156682028,
      "grad_norm": 0.0446787066757679,
      "learning_rate": 2.4550898203592816e-05,
      "loss": 0.0003,
      "step": 1350
    },
    {
      "epoch": 6.267281105990784,
      "grad_norm": 0.45139700174331665,
      "learning_rate": 2.4251497005988023e-05,
      "loss": 0.0033,
      "step": 1360
    },
    {
      "epoch": 6.313364055299539,
      "grad_norm": 0.06293760240077972,
      "learning_rate": 2.3952095808383234e-05,
      "loss": 0.0011,
      "step": 1370
    },
    {
      "epoch": 6.359447004608295,
      "grad_norm": 0.0843488797545433,
      "learning_rate": 2.3652694610778445e-05,
      "loss": 0.001,
      "step": 1380
    },
    {
      "epoch": 6.405529953917051,
      "grad_norm": 0.013393334113061428,
      "learning_rate": 2.3353293413173656e-05,
      "loss": 0.0006,
      "step": 1390
    },
    {
      "epoch": 6.451612903225806,
      "grad_norm": 0.016619408503174782,
      "learning_rate": 2.3053892215568866e-05,
      "loss": 0.0013,
      "step": 1400
    },
    {
      "epoch": 6.451612903225806,
      "eval_loss": 0.00010883880167966709,
      "eval_runtime": 3.3278,
      "eval_samples_per_second": 65.509,
      "eval_steps_per_second": 8.414,
      "step": 1400
    },
    {
      "epoch": 6.497695852534562,
      "grad_norm": 0.12127891927957535,
      "learning_rate": 2.275449101796407e-05,
      "loss": 0.0007,
      "step": 1410
    },
    {
      "epoch": 6.543778801843318,
      "grad_norm": 0.026304908096790314,
      "learning_rate": 2.245508982035928e-05,
      "loss": 0.0007,
      "step": 1420
    },
    {
      "epoch": 6.589861751152074,
      "grad_norm": 0.11873284727334976,
      "learning_rate": 2.2155688622754492e-05,
      "loss": 0.0014,
      "step": 1430
    },
    {
      "epoch": 6.635944700460829,
      "grad_norm": 0.03314080461859703,
      "learning_rate": 2.1856287425149703e-05,
      "loss": 0.0009,
      "step": 1440
    },
    {
      "epoch": 6.682027649769585,
      "grad_norm": 0.02117510698735714,
      "learning_rate": 2.155688622754491e-05,
      "loss": 0.001,
      "step": 1450
    },
    {
      "epoch": 6.728110599078341,
      "grad_norm": 0.019696509465575218,
      "learning_rate": 2.125748502994012e-05,
      "loss": 0.0006,
      "step": 1460
    },
    {
      "epoch": 6.774193548387097,
      "grad_norm": 0.2653408348560333,
      "learning_rate": 2.095808383233533e-05,
      "loss": 0.0004,
      "step": 1470
    },
    {
      "epoch": 6.820276497695852,
      "grad_norm": 0.20925992727279663,
      "learning_rate": 2.065868263473054e-05,
      "loss": 0.0014,
      "step": 1480
    },
    {
      "epoch": 6.8663594470046085,
      "grad_norm": 0.02338450960814953,
      "learning_rate": 2.035928143712575e-05,
      "loss": 0.0005,
      "step": 1490
    },
    {
      "epoch": 6.912442396313364,
      "grad_norm": 0.022023536264896393,
      "learning_rate": 2.0059880239520957e-05,
      "loss": 0.0021,
      "step": 1500
    },
    {
      "epoch": 6.912442396313364,
      "eval_loss": 7.662396819796413e-05,
      "eval_runtime": 3.2564,
      "eval_samples_per_second": 66.946,
      "eval_steps_per_second": 8.599,
      "step": 1500
    },
    {
      "epoch": 6.95852534562212,
      "grad_norm": 0.008935282938182354,
      "learning_rate": 1.9760479041916168e-05,
      "loss": 0.0008,
      "step": 1510
    },
    {
      "epoch": 7.0046082949308754,
      "grad_norm": 0.24162651598453522,
      "learning_rate": 1.946107784431138e-05,
      "loss": 0.0006,
      "step": 1520
    },
    {
      "epoch": 7.050691244239632,
      "grad_norm": 0.11838989704847336,
      "learning_rate": 1.916167664670659e-05,
      "loss": 0.0009,
      "step": 1530
    },
    {
      "epoch": 7.096774193548387,
      "grad_norm": 0.015380925498902798,
      "learning_rate": 1.8862275449101797e-05,
      "loss": 0.0004,
      "step": 1540
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.005185112822800875,
      "learning_rate": 1.8562874251497005e-05,
      "loss": 0.0006,
      "step": 1550
    },
    {
      "epoch": 7.188940092165899,
      "grad_norm": 0.04063088446855545,
      "learning_rate": 1.8263473053892215e-05,
      "loss": 0.0008,
      "step": 1560
    },
    {
      "epoch": 7.235023041474655,
      "grad_norm": 0.01554267480969429,
      "learning_rate": 1.7964071856287426e-05,
      "loss": 0.0005,
      "step": 1570
    },
    {
      "epoch": 7.28110599078341,
      "grad_norm": 0.002975007053464651,
      "learning_rate": 1.7664670658682637e-05,
      "loss": 0.001,
      "step": 1580
    },
    {
      "epoch": 7.3271889400921655,
      "grad_norm": 0.001956840045750141,
      "learning_rate": 1.7365269461077845e-05,
      "loss": 0.0021,
      "step": 1590
    },
    {
      "epoch": 7.373271889400922,
      "grad_norm": 0.02044929563999176,
      "learning_rate": 1.7065868263473055e-05,
      "loss": 0.0011,
      "step": 1600
    },
    {
      "epoch": 7.373271889400922,
      "eval_loss": 6.119311001384631e-05,
      "eval_runtime": 3.4351,
      "eval_samples_per_second": 63.462,
      "eval_steps_per_second": 8.151,
      "step": 1600
    },
    {
      "epoch": 7.419354838709677,
      "grad_norm": 0.026692310348153114,
      "learning_rate": 1.6766467065868263e-05,
      "loss": 0.0005,
      "step": 1610
    },
    {
      "epoch": 7.465437788018433,
      "grad_norm": 0.0017774292500689626,
      "learning_rate": 1.6467065868263474e-05,
      "loss": 0.0005,
      "step": 1620
    },
    {
      "epoch": 7.511520737327189,
      "grad_norm": 0.004613459575921297,
      "learning_rate": 1.6167664670658684e-05,
      "loss": 0.001,
      "step": 1630
    },
    {
      "epoch": 7.557603686635945,
      "grad_norm": 0.18013201653957367,
      "learning_rate": 1.5868263473053892e-05,
      "loss": 0.0017,
      "step": 1640
    },
    {
      "epoch": 7.6036866359447,
      "grad_norm": 0.17736230790615082,
      "learning_rate": 1.5568862275449103e-05,
      "loss": 0.0006,
      "step": 1650
    },
    {
      "epoch": 7.649769585253456,
      "grad_norm": 0.09855789691209793,
      "learning_rate": 1.5269461077844313e-05,
      "loss": 0.0014,
      "step": 1660
    },
    {
      "epoch": 7.695852534562212,
      "grad_norm": 0.007090989500284195,
      "learning_rate": 1.497005988023952e-05,
      "loss": 0.0008,
      "step": 1670
    },
    {
      "epoch": 7.741935483870968,
      "grad_norm": 0.016133766621351242,
      "learning_rate": 1.467065868263473e-05,
      "loss": 0.0009,
      "step": 1680
    },
    {
      "epoch": 7.788018433179723,
      "grad_norm": 0.053114525973796844,
      "learning_rate": 1.437125748502994e-05,
      "loss": 0.0006,
      "step": 1690
    },
    {
      "epoch": 7.8341013824884795,
      "grad_norm": 0.17376911640167236,
      "learning_rate": 1.407185628742515e-05,
      "loss": 0.0009,
      "step": 1700
    },
    {
      "epoch": 7.8341013824884795,
      "eval_loss": 5.582916855928488e-05,
      "eval_runtime": 4.4379,
      "eval_samples_per_second": 49.123,
      "eval_steps_per_second": 6.309,
      "step": 1700
    },
    {
      "epoch": 7.880184331797235,
      "grad_norm": 0.11870471388101578,
      "learning_rate": 1.377245508982036e-05,
      "loss": 0.0007,
      "step": 1710
    },
    {
      "epoch": 7.926267281105991,
      "grad_norm": 0.10822280496358871,
      "learning_rate": 1.347305389221557e-05,
      "loss": 0.0007,
      "step": 1720
    },
    {
      "epoch": 7.972350230414746,
      "grad_norm": 0.0021072844974696636,
      "learning_rate": 1.317365269461078e-05,
      "loss": 0.0009,
      "step": 1730
    },
    {
      "epoch": 8.018433179723502,
      "grad_norm": 0.14357006549835205,
      "learning_rate": 1.2874251497005988e-05,
      "loss": 0.0006,
      "step": 1740
    },
    {
      "epoch": 8.064516129032258,
      "grad_norm": 0.03131711110472679,
      "learning_rate": 1.2574850299401197e-05,
      "loss": 0.0005,
      "step": 1750
    },
    {
      "epoch": 8.110599078341014,
      "grad_norm": 0.0025851288810372353,
      "learning_rate": 1.2275449101796408e-05,
      "loss": 0.0008,
      "step": 1760
    },
    {
      "epoch": 8.156682027649769,
      "grad_norm": 0.008784031495451927,
      "learning_rate": 1.1976047904191617e-05,
      "loss": 0.0006,
      "step": 1770
    },
    {
      "epoch": 8.202764976958525,
      "grad_norm": 0.0024391720071434975,
      "learning_rate": 1.1676646706586828e-05,
      "loss": 0.0006,
      "step": 1780
    },
    {
      "epoch": 8.248847926267281,
      "grad_norm": 0.011719484813511372,
      "learning_rate": 1.1377245508982035e-05,
      "loss": 0.0004,
      "step": 1790
    },
    {
      "epoch": 8.294930875576037,
      "grad_norm": 0.046767547726631165,
      "learning_rate": 1.1077844311377246e-05,
      "loss": 0.0006,
      "step": 1800
    },
    {
      "epoch": 8.294930875576037,
      "eval_loss": 5.283029531710781e-05,
      "eval_runtime": 3.1316,
      "eval_samples_per_second": 69.614,
      "eval_steps_per_second": 8.941,
      "step": 1800
    },
    {
      "epoch": 8.341013824884792,
      "grad_norm": 0.0039721522480249405,
      "learning_rate": 1.0778443113772455e-05,
      "loss": 0.0009,
      "step": 1810
    },
    {
      "epoch": 8.387096774193548,
      "grad_norm": 0.05384698510169983,
      "learning_rate": 1.0479041916167664e-05,
      "loss": 0.0004,
      "step": 1820
    },
    {
      "epoch": 8.433179723502304,
      "grad_norm": 0.011257100850343704,
      "learning_rate": 1.0179640718562875e-05,
      "loss": 0.0004,
      "step": 1830
    },
    {
      "epoch": 8.47926267281106,
      "grad_norm": 0.024923549965023994,
      "learning_rate": 9.880239520958084e-06,
      "loss": 0.0006,
      "step": 1840
    },
    {
      "epoch": 8.525345622119815,
      "grad_norm": 0.004078418016433716,
      "learning_rate": 9.580838323353295e-06,
      "loss": 0.0004,
      "step": 1850
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 0.28670749068260193,
      "learning_rate": 9.281437125748502e-06,
      "loss": 0.0015,
      "step": 1860
    },
    {
      "epoch": 8.617511520737327,
      "grad_norm": 0.02012777328491211,
      "learning_rate": 8.982035928143713e-06,
      "loss": 0.0017,
      "step": 1870
    },
    {
      "epoch": 8.663594470046084,
      "grad_norm": 0.12636412680149078,
      "learning_rate": 8.682634730538922e-06,
      "loss": 0.0006,
      "step": 1880
    },
    {
      "epoch": 8.709677419354838,
      "grad_norm": 0.008884744718670845,
      "learning_rate": 8.383233532934131e-06,
      "loss": 0.0005,
      "step": 1890
    },
    {
      "epoch": 8.755760368663594,
      "grad_norm": 0.0024703724775463343,
      "learning_rate": 8.083832335329342e-06,
      "loss": 0.0013,
      "step": 1900
    },
    {
      "epoch": 8.755760368663594,
      "eval_loss": 5.205194611335173e-05,
      "eval_runtime": 3.3018,
      "eval_samples_per_second": 66.025,
      "eval_steps_per_second": 8.48,
      "step": 1900
    },
    {
      "epoch": 8.80184331797235,
      "grad_norm": 0.017882520332932472,
      "learning_rate": 7.784431137724551e-06,
      "loss": 0.0002,
      "step": 1910
    },
    {
      "epoch": 8.847926267281107,
      "grad_norm": 0.006054180208593607,
      "learning_rate": 7.48502994011976e-06,
      "loss": 0.0006,
      "step": 1920
    },
    {
      "epoch": 8.894009216589861,
      "grad_norm": 0.045372121036052704,
      "learning_rate": 7.18562874251497e-06,
      "loss": 0.0006,
      "step": 1930
    },
    {
      "epoch": 8.940092165898617,
      "grad_norm": 0.008154095150530338,
      "learning_rate": 6.88622754491018e-06,
      "loss": 0.0012,
      "step": 1940
    },
    {
      "epoch": 8.986175115207374,
      "grad_norm": 0.02607155404984951,
      "learning_rate": 6.58682634730539e-06,
      "loss": 0.0006,
      "step": 1950
    },
    {
      "epoch": 9.03225806451613,
      "grad_norm": 0.0042995610274374485,
      "learning_rate": 6.2874251497005985e-06,
      "loss": 0.0004,
      "step": 1960
    },
    {
      "epoch": 9.078341013824884,
      "grad_norm": 0.2510429918766022,
      "learning_rate": 5.9880239520958085e-06,
      "loss": 0.0008,
      "step": 1970
    },
    {
      "epoch": 9.12442396313364,
      "grad_norm": 0.0024167278315871954,
      "learning_rate": 5.688622754491018e-06,
      "loss": 0.0002,
      "step": 1980
    },
    {
      "epoch": 9.170506912442397,
      "grad_norm": 0.009431278333067894,
      "learning_rate": 5.3892215568862275e-06,
      "loss": 0.001,
      "step": 1990
    },
    {
      "epoch": 9.216589861751151,
      "grad_norm": 0.002398374956101179,
      "learning_rate": 5.0898203592814375e-06,
      "loss": 0.0011,
      "step": 2000
    },
    {
      "epoch": 9.216589861751151,
      "eval_loss": 4.792965773958713e-05,
      "eval_runtime": 4.0542,
      "eval_samples_per_second": 53.771,
      "eval_steps_per_second": 6.906,
      "step": 2000
    }
  ],
  "logging_steps": 10,
  "max_steps": 2170,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
