{
  "best_metric": 0.0003016693517565727,
  "best_model_checkpoint": "/workspace/rtp/CF-PepMLM/checkpoints/checkpoint-1000",
  "epoch": 4.6082949308755765,
  "eval_steps": 100,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04608294930875576,
      "grad_norm": 1.2221239805221558,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.7734,
      "step": 10
    },
    {
      "epoch": 0.09216589861751152,
      "grad_norm": 1.2903002500534058,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.795,
      "step": 20
    },
    {
      "epoch": 0.1382488479262673,
      "grad_norm": 0.9074258208274841,
      "learning_rate": 3e-06,
      "loss": 0.7743,
      "step": 30
    },
    {
      "epoch": 0.18433179723502305,
      "grad_norm": 1.1783366203308105,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.7928,
      "step": 40
    },
    {
      "epoch": 0.2304147465437788,
      "grad_norm": 0.913509726524353,
      "learning_rate": 5e-06,
      "loss": 0.7656,
      "step": 50
    },
    {
      "epoch": 0.2764976958525346,
      "grad_norm": 0.971287727355957,
      "learning_rate": 6e-06,
      "loss": 0.7406,
      "step": 60
    },
    {
      "epoch": 0.3225806451612903,
      "grad_norm": 0.8465772271156311,
      "learning_rate": 7.000000000000001e-06,
      "loss": 0.7102,
      "step": 70
    },
    {
      "epoch": 0.3686635944700461,
      "grad_norm": 1.177011489868164,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.6897,
      "step": 80
    },
    {
      "epoch": 0.4147465437788018,
      "grad_norm": 1.1783441305160522,
      "learning_rate": 9e-06,
      "loss": 0.6719,
      "step": 90
    },
    {
      "epoch": 0.4608294930875576,
      "grad_norm": 1.2005335092544556,
      "learning_rate": 1e-05,
      "loss": 0.606,
      "step": 100
    },
    {
      "epoch": 0.4608294930875576,
      "eval_loss": 0.5518519282341003,
      "eval_runtime": 3.8436,
      "eval_samples_per_second": 56.717,
      "eval_steps_per_second": 7.285,
      "step": 100
    },
    {
      "epoch": 0.5069124423963134,
      "grad_norm": 1.5589687824249268,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.5516,
      "step": 110
    },
    {
      "epoch": 0.5529953917050692,
      "grad_norm": 1.4523738622665405,
      "learning_rate": 1.2e-05,
      "loss": 0.5204,
      "step": 120
    },
    {
      "epoch": 0.5990783410138248,
      "grad_norm": 1.247963309288025,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.3851,
      "step": 130
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 1.0782917737960815,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.3266,
      "step": 140
    },
    {
      "epoch": 0.6912442396313364,
      "grad_norm": 0.7613620162010193,
      "learning_rate": 1.5e-05,
      "loss": 0.2864,
      "step": 150
    },
    {
      "epoch": 0.7373271889400922,
      "grad_norm": 0.9301382899284363,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.258,
      "step": 160
    },
    {
      "epoch": 0.783410138248848,
      "grad_norm": 0.9205523729324341,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.2286,
      "step": 170
    },
    {
      "epoch": 0.8294930875576036,
      "grad_norm": 0.7904914617538452,
      "learning_rate": 1.8e-05,
      "loss": 0.201,
      "step": 180
    },
    {
      "epoch": 0.8755760368663594,
      "grad_norm": 0.6755183339118958,
      "learning_rate": 1.9e-05,
      "loss": 0.1537,
      "step": 190
    },
    {
      "epoch": 0.9216589861751152,
      "grad_norm": 0.7571019530296326,
      "learning_rate": 2e-05,
      "loss": 0.1209,
      "step": 200
    },
    {
      "epoch": 0.9216589861751152,
      "eval_loss": 0.08680877089500427,
      "eval_runtime": 3.468,
      "eval_samples_per_second": 62.86,
      "eval_steps_per_second": 8.074,
      "step": 200
    },
    {
      "epoch": 0.967741935483871,
      "grad_norm": 0.7238255739212036,
      "learning_rate": 2.1e-05,
      "loss": 0.1068,
      "step": 210
    },
    {
      "epoch": 1.0138248847926268,
      "grad_norm": 0.47162294387817383,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.0876,
      "step": 220
    },
    {
      "epoch": 1.0599078341013826,
      "grad_norm": 0.5361238718032837,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.0793,
      "step": 230
    },
    {
      "epoch": 1.1059907834101383,
      "grad_norm": 0.4974692165851593,
      "learning_rate": 2.4e-05,
      "loss": 0.0589,
      "step": 240
    },
    {
      "epoch": 1.1520737327188941,
      "grad_norm": 0.46764472126960754,
      "learning_rate": 2.5e-05,
      "loss": 0.0515,
      "step": 250
    },
    {
      "epoch": 1.1981566820276497,
      "grad_norm": 0.6306203603744507,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.0537,
      "step": 260
    },
    {
      "epoch": 1.2442396313364055,
      "grad_norm": 0.48413780331611633,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.0377,
      "step": 270
    },
    {
      "epoch": 1.2903225806451613,
      "grad_norm": 0.48220014572143555,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.0377,
      "step": 280
    },
    {
      "epoch": 1.336405529953917,
      "grad_norm": 0.26070141792297363,
      "learning_rate": 2.9e-05,
      "loss": 0.0353,
      "step": 290
    },
    {
      "epoch": 1.3824884792626728,
      "grad_norm": 0.2717057764530182,
      "learning_rate": 3e-05,
      "loss": 0.0317,
      "step": 300
    },
    {
      "epoch": 1.3824884792626728,
      "eval_loss": 0.018590880557894707,
      "eval_runtime": 3.6498,
      "eval_samples_per_second": 59.73,
      "eval_steps_per_second": 7.672,
      "step": 300
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.5223829746246338,
      "learning_rate": 3.1e-05,
      "loss": 0.0365,
      "step": 310
    },
    {
      "epoch": 1.4746543778801844,
      "grad_norm": 0.340888649225235,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.0279,
      "step": 320
    },
    {
      "epoch": 1.52073732718894,
      "grad_norm": 0.3112410306930542,
      "learning_rate": 3.3e-05,
      "loss": 0.0262,
      "step": 330
    },
    {
      "epoch": 1.5668202764976957,
      "grad_norm": 0.29125121235847473,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0221,
      "step": 340
    },
    {
      "epoch": 1.6129032258064515,
      "grad_norm": 0.41481947898864746,
      "learning_rate": 3.5e-05,
      "loss": 0.021,
      "step": 350
    },
    {
      "epoch": 1.6589861751152073,
      "grad_norm": 0.33511883020401,
      "learning_rate": 3.6e-05,
      "loss": 0.0206,
      "step": 360
    },
    {
      "epoch": 1.705069124423963,
      "grad_norm": 0.41893166303634644,
      "learning_rate": 3.7e-05,
      "loss": 0.0135,
      "step": 370
    },
    {
      "epoch": 1.7511520737327189,
      "grad_norm": 0.357644259929657,
      "learning_rate": 3.8e-05,
      "loss": 0.022,
      "step": 380
    },
    {
      "epoch": 1.7972350230414746,
      "grad_norm": 0.18183016777038574,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.0123,
      "step": 390
    },
    {
      "epoch": 1.8433179723502304,
      "grad_norm": 0.29831454157829285,
      "learning_rate": 4e-05,
      "loss": 0.0135,
      "step": 400
    },
    {
      "epoch": 1.8433179723502304,
      "eval_loss": 0.0062129441648721695,
      "eval_runtime": 4.0426,
      "eval_samples_per_second": 53.926,
      "eval_steps_per_second": 6.926,
      "step": 400
    },
    {
      "epoch": 1.8894009216589862,
      "grad_norm": 0.22957932949066162,
      "learning_rate": 4.1e-05,
      "loss": 0.0123,
      "step": 410
    },
    {
      "epoch": 1.935483870967742,
      "grad_norm": 0.16631853580474854,
      "learning_rate": 4.2e-05,
      "loss": 0.0101,
      "step": 420
    },
    {
      "epoch": 1.9815668202764978,
      "grad_norm": 0.3713280260562897,
      "learning_rate": 4.3e-05,
      "loss": 0.0133,
      "step": 430
    },
    {
      "epoch": 2.0276497695852536,
      "grad_norm": 0.24464811384677887,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.0122,
      "step": 440
    },
    {
      "epoch": 2.0737327188940093,
      "grad_norm": 0.14365676045417786,
      "learning_rate": 4.5e-05,
      "loss": 0.009,
      "step": 450
    },
    {
      "epoch": 2.119815668202765,
      "grad_norm": 0.37955477833747864,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.011,
      "step": 460
    },
    {
      "epoch": 2.165898617511521,
      "grad_norm": 0.34527018666267395,
      "learning_rate": 4.7e-05,
      "loss": 0.0103,
      "step": 470
    },
    {
      "epoch": 2.2119815668202767,
      "grad_norm": 0.21032993495464325,
      "learning_rate": 4.8e-05,
      "loss": 0.0082,
      "step": 480
    },
    {
      "epoch": 2.258064516129032,
      "grad_norm": 0.17407621443271637,
      "learning_rate": 4.9e-05,
      "loss": 0.0073,
      "step": 490
    },
    {
      "epoch": 2.3041474654377883,
      "grad_norm": 0.30856654047966003,
      "learning_rate": 5e-05,
      "loss": 0.0103,
      "step": 500
    },
    {
      "epoch": 2.3041474654377883,
      "eval_loss": 0.0030326282139867544,
      "eval_runtime": 5.337,
      "eval_samples_per_second": 40.847,
      "eval_steps_per_second": 5.246,
      "step": 500
    },
    {
      "epoch": 2.3502304147465436,
      "grad_norm": 0.23411279916763306,
      "learning_rate": 4.970059880239521e-05,
      "loss": 0.0087,
      "step": 510
    },
    {
      "epoch": 2.3963133640552994,
      "grad_norm": 0.18469040095806122,
      "learning_rate": 4.9401197604790424e-05,
      "loss": 0.0057,
      "step": 520
    },
    {
      "epoch": 2.442396313364055,
      "grad_norm": 0.15716958045959473,
      "learning_rate": 4.910179640718563e-05,
      "loss": 0.006,
      "step": 530
    },
    {
      "epoch": 2.488479262672811,
      "grad_norm": 0.10877557098865509,
      "learning_rate": 4.8802395209580846e-05,
      "loss": 0.0076,
      "step": 540
    },
    {
      "epoch": 2.5345622119815667,
      "grad_norm": 0.18851915001869202,
      "learning_rate": 4.8502994011976046e-05,
      "loss": 0.0078,
      "step": 550
    },
    {
      "epoch": 2.5806451612903225,
      "grad_norm": 0.1537848562002182,
      "learning_rate": 4.820359281437126e-05,
      "loss": 0.0048,
      "step": 560
    },
    {
      "epoch": 2.6267281105990783,
      "grad_norm": 0.18426953256130219,
      "learning_rate": 4.790419161676647e-05,
      "loss": 0.0043,
      "step": 570
    },
    {
      "epoch": 2.672811059907834,
      "grad_norm": 0.19603843986988068,
      "learning_rate": 4.7604790419161675e-05,
      "loss": 0.0048,
      "step": 580
    },
    {
      "epoch": 2.71889400921659,
      "grad_norm": 0.09878431260585785,
      "learning_rate": 4.730538922155689e-05,
      "loss": 0.008,
      "step": 590
    },
    {
      "epoch": 2.7649769585253456,
      "grad_norm": 0.1926334798336029,
      "learning_rate": 4.70059880239521e-05,
      "loss": 0.0051,
      "step": 600
    },
    {
      "epoch": 2.7649769585253456,
      "eval_loss": 0.0014930713223293424,
      "eval_runtime": 3.711,
      "eval_samples_per_second": 58.745,
      "eval_steps_per_second": 7.545,
      "step": 600
    },
    {
      "epoch": 2.8110599078341014,
      "grad_norm": 0.11369042843580246,
      "learning_rate": 4.670658682634731e-05,
      "loss": 0.0055,
      "step": 610
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.1356334388256073,
      "learning_rate": 4.640718562874252e-05,
      "loss": 0.0036,
      "step": 620
    },
    {
      "epoch": 2.903225806451613,
      "grad_norm": 0.20589186251163483,
      "learning_rate": 4.610778443113773e-05,
      "loss": 0.006,
      "step": 630
    },
    {
      "epoch": 2.9493087557603688,
      "grad_norm": 0.1344430148601532,
      "learning_rate": 4.580838323353293e-05,
      "loss": 0.0025,
      "step": 640
    },
    {
      "epoch": 2.9953917050691246,
      "grad_norm": 0.18633319437503815,
      "learning_rate": 4.550898203592814e-05,
      "loss": 0.0042,
      "step": 650
    },
    {
      "epoch": 3.0414746543778803,
      "grad_norm": 0.18155881762504578,
      "learning_rate": 4.5209580838323355e-05,
      "loss": 0.0044,
      "step": 660
    },
    {
      "epoch": 3.087557603686636,
      "grad_norm": 0.1386127471923828,
      "learning_rate": 4.491017964071856e-05,
      "loss": 0.0033,
      "step": 670
    },
    {
      "epoch": 3.133640552995392,
      "grad_norm": 0.15597963333129883,
      "learning_rate": 4.4610778443113777e-05,
      "loss": 0.003,
      "step": 680
    },
    {
      "epoch": 3.1797235023041477,
      "grad_norm": 0.12742440402507782,
      "learning_rate": 4.4311377245508984e-05,
      "loss": 0.0033,
      "step": 690
    },
    {
      "epoch": 3.225806451612903,
      "grad_norm": 0.027078034356236458,
      "learning_rate": 4.40119760479042e-05,
      "loss": 0.0012,
      "step": 700
    },
    {
      "epoch": 3.225806451612903,
      "eval_loss": 0.0009080949239432812,
      "eval_runtime": 3.7791,
      "eval_samples_per_second": 57.686,
      "eval_steps_per_second": 7.409,
      "step": 700
    },
    {
      "epoch": 3.271889400921659,
      "grad_norm": 0.25669535994529724,
      "learning_rate": 4.3712574850299406e-05,
      "loss": 0.0038,
      "step": 710
    },
    {
      "epoch": 3.3179723502304146,
      "grad_norm": 0.2486574500799179,
      "learning_rate": 4.341317365269461e-05,
      "loss": 0.0047,
      "step": 720
    },
    {
      "epoch": 3.3640552995391704,
      "grad_norm": 0.20283110439777374,
      "learning_rate": 4.311377245508982e-05,
      "loss": 0.0023,
      "step": 730
    },
    {
      "epoch": 3.410138248847926,
      "grad_norm": 0.0888674184679985,
      "learning_rate": 4.281437125748503e-05,
      "loss": 0.0017,
      "step": 740
    },
    {
      "epoch": 3.456221198156682,
      "grad_norm": 0.17090241611003876,
      "learning_rate": 4.251497005988024e-05,
      "loss": 0.0025,
      "step": 750
    },
    {
      "epoch": 3.5023041474654377,
      "grad_norm": 0.19521477818489075,
      "learning_rate": 4.221556886227545e-05,
      "loss": 0.0033,
      "step": 760
    },
    {
      "epoch": 3.5483870967741935,
      "grad_norm": 0.07247144728899002,
      "learning_rate": 4.191616766467066e-05,
      "loss": 0.0014,
      "step": 770
    },
    {
      "epoch": 3.5944700460829493,
      "grad_norm": 0.14422035217285156,
      "learning_rate": 4.161676646706587e-05,
      "loss": 0.0027,
      "step": 780
    },
    {
      "epoch": 3.640552995391705,
      "grad_norm": 0.05749085545539856,
      "learning_rate": 4.131736526946108e-05,
      "loss": 0.0027,
      "step": 790
    },
    {
      "epoch": 3.686635944700461,
      "grad_norm": 0.11122436821460724,
      "learning_rate": 4.101796407185629e-05,
      "loss": 0.0017,
      "step": 800
    },
    {
      "epoch": 3.686635944700461,
      "eval_loss": 0.000741194817237556,
      "eval_runtime": 3.2183,
      "eval_samples_per_second": 67.737,
      "eval_steps_per_second": 8.7,
      "step": 800
    },
    {
      "epoch": 3.7327188940092166,
      "grad_norm": 0.16310246288776398,
      "learning_rate": 4.07185628742515e-05,
      "loss": 0.006,
      "step": 810
    },
    {
      "epoch": 3.7788018433179724,
      "grad_norm": 0.27053704857826233,
      "learning_rate": 4.041916167664671e-05,
      "loss": 0.0031,
      "step": 820
    },
    {
      "epoch": 3.824884792626728,
      "grad_norm": 0.03771095722913742,
      "learning_rate": 4.0119760479041915e-05,
      "loss": 0.0018,
      "step": 830
    },
    {
      "epoch": 3.870967741935484,
      "grad_norm": 0.2837746739387512,
      "learning_rate": 3.982035928143712e-05,
      "loss": 0.0039,
      "step": 840
    },
    {
      "epoch": 3.9170506912442398,
      "grad_norm": 0.3046124279499054,
      "learning_rate": 3.9520958083832336e-05,
      "loss": 0.0027,
      "step": 850
    },
    {
      "epoch": 3.9631336405529956,
      "grad_norm": 0.06274067610502243,
      "learning_rate": 3.9221556886227544e-05,
      "loss": 0.0029,
      "step": 860
    },
    {
      "epoch": 4.009216589861751,
      "grad_norm": 0.1926690936088562,
      "learning_rate": 3.892215568862276e-05,
      "loss": 0.0052,
      "step": 870
    },
    {
      "epoch": 4.055299539170507,
      "grad_norm": 0.07665092498064041,
      "learning_rate": 3.8622754491017966e-05,
      "loss": 0.0014,
      "step": 880
    },
    {
      "epoch": 4.1013824884792625,
      "grad_norm": 0.06854434311389923,
      "learning_rate": 3.832335329341318e-05,
      "loss": 0.0013,
      "step": 890
    },
    {
      "epoch": 4.147465437788019,
      "grad_norm": 0.038714054971933365,
      "learning_rate": 3.802395209580839e-05,
      "loss": 0.0009,
      "step": 900
    },
    {
      "epoch": 4.147465437788019,
      "eval_loss": 0.0004275927203707397,
      "eval_runtime": 2.477,
      "eval_samples_per_second": 88.011,
      "eval_steps_per_second": 11.304,
      "step": 900
    },
    {
      "epoch": 4.193548387096774,
      "grad_norm": 0.1802065670490265,
      "learning_rate": 3.7724550898203595e-05,
      "loss": 0.0029,
      "step": 910
    },
    {
      "epoch": 4.23963133640553,
      "grad_norm": 0.0067209540866315365,
      "learning_rate": 3.74251497005988e-05,
      "loss": 0.001,
      "step": 920
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.11563533544540405,
      "learning_rate": 3.712574850299401e-05,
      "loss": 0.0018,
      "step": 930
    },
    {
      "epoch": 4.331797235023042,
      "grad_norm": 0.1913885623216629,
      "learning_rate": 3.6826347305389224e-05,
      "loss": 0.0032,
      "step": 940
    },
    {
      "epoch": 4.377880184331797,
      "grad_norm": 0.006824429612606764,
      "learning_rate": 3.652694610778443e-05,
      "loss": 0.0013,
      "step": 950
    },
    {
      "epoch": 4.423963133640553,
      "grad_norm": 0.12576280534267426,
      "learning_rate": 3.6227544910179645e-05,
      "loss": 0.0018,
      "step": 960
    },
    {
      "epoch": 4.470046082949309,
      "grad_norm": 0.21926555037498474,
      "learning_rate": 3.592814371257485e-05,
      "loss": 0.0023,
      "step": 970
    },
    {
      "epoch": 4.516129032258064,
      "grad_norm": 0.15565291047096252,
      "learning_rate": 3.562874251497006e-05,
      "loss": 0.0008,
      "step": 980
    },
    {
      "epoch": 4.56221198156682,
      "grad_norm": 0.031143641099333763,
      "learning_rate": 3.5329341317365274e-05,
      "loss": 0.0013,
      "step": 990
    },
    {
      "epoch": 4.6082949308755765,
      "grad_norm": 0.15209895372390747,
      "learning_rate": 3.502994011976048e-05,
      "loss": 0.0014,
      "step": 1000
    },
    {
      "epoch": 4.6082949308755765,
      "eval_loss": 0.0003016693517565727,
      "eval_runtime": 3.3643,
      "eval_samples_per_second": 64.799,
      "eval_steps_per_second": 8.323,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 2170,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
